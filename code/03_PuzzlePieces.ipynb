{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjYUroGI0tv1mr8MDrecx4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu --quiet"
      ],
      "metadata": {
        "id": "upVURDE_wmXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "from conllu import parse\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "3ri1a4KM2xps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/krfis/CLthesis.git --quiet"
      ],
      "metadata": {
        "id": "dhIFJ3kcz_Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getsize_allinfolder(folder_path):\n",
        "  '''prints token counts in all files of a folder'''\n",
        "\n",
        "  for file in os.listdir(folder_path):\n",
        "    path = os.path.join(folder_path, file)\n",
        "    if path.endswith(\".conllu\"):\n",
        "      with open(path, \"r\", encoding=\"utf-8\") as input:\n",
        "        data = input.read()\n",
        "      sentences = parse(data)\n",
        "      print(f'Number of sentences in {path} : {len(sentences)}')\n",
        "      token_count = count_tokens(sentences)\n",
        "      print(f'Number of tokens in {path} : {token_count}')\n",
        "      print()"
      ],
      "metadata": {
        "id": "JxDKC8H1pOji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(dataset):\n",
        "  '''counts tokens in a conllu dataset\n",
        "  returns token count : int'''\n",
        "\n",
        "  counter = 0\n",
        "  for sentence in dataset:\n",
        "    for token in sentence:\n",
        "      counter += 1\n",
        "  return counter"
      ],
      "metadata": {
        "id": "ojwyK6S6JHEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(path):\n",
        "  '''parses conllu file\n",
        "  returns parsed conllu file : list(TokenList)'''\n",
        "\n",
        "  with open(path, \"r\", encoding=\"utf-8\") as dataset:\n",
        "    input = dataset.read()\n",
        "    parsed = parse(input)\n",
        "  return parsed"
      ],
      "metadata": {
        "id": "ny9rltMUi5Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write(content):\n",
        "  '''writes content of TokenLists to output file'''\n",
        "\n",
        "  with open(\"output.train\", \"w\", encoding=\"utf-8\") as output:\n",
        "    for sent in content:\n",
        "      output.write(sent.serialize())"
      ],
      "metadata": {
        "id": "CPnL16d3kyF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paths to files to be combined (puzzle-pieces)\n",
        "\n",
        "puzzle1 = \"/content/CLthesis/data/balanced-new/_puzzle-pieces/for-scandi-multisource-2/ice-30k-1.train\"\n",
        "puzzle2 = \"/content/CLthesis/data/balanced-new/_puzzle-pieces/for-support-buckets/geo/gle-15k-1.train\"\n",
        "puzzle3 = \"/content/CLthesis/data/balanced-new/_puzzle-pieces/for-support-buckets/geo/gla-15k-1.train\"\n",
        "puzzle4 = \"/content/CLthesis/data/balanced-new/_puzzle-pieces/for-support-buckets/synt/slv-1k.dev\""
      ],
      "metadata": {
        "id": "CrOMMzg-iR5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = process(puzzle1)\n",
        "data2 = process(puzzle2)\n",
        "data3 = process(puzzle3)\n",
        "data4 = process(puzzle4)"
      ],
      "metadata": {
        "id": "obe38RGNjFu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'File 1:')\n",
        "print(f'Number of sentences: {len(data1)}')\n",
        "token_count1 = count_tokens(data1)\n",
        "print(f'Number of tokens: {token_count1}')\n",
        "print()\n",
        "print(f'File 2:')\n",
        "print(f'Number of sentences: {len(data2)}')\n",
        "token_count2 = count_tokens(data2)\n",
        "print(f'Number of tokens: {token_count2}')\n",
        "print()\n",
        "print(f'File 3:')\n",
        "print(f'Number of sentences: {len(data3)}')\n",
        "token_count3 = count_tokens(data3)\n",
        "print(f'Number of tokens: {token_count3}')\n",
        "print()\n",
        "print(f'File 4:')\n",
        "print(f'Number of sentences: {len(data4)}')\n",
        "token_count4 = count_tokens(data4)\n",
        "print(f'Number of tokens: {token_count4}')"
      ],
      "metadata": {
        "id": "EqjWVwwkjTZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = data1 + data2 + data3 + data4  # combine data"
      ],
      "metadata": {
        "id": "WRNTI1Fw4DwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'New file')\n",
        "print(f'Number of sentences: {len(new_data)}')\n",
        "token_count4 = count_tokens(new_data)\n",
        "print(f'Number of tokens: {token_count4}')"
      ],
      "metadata": {
        "id": "-y-nFD9N4Ieq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data[0]"
      ],
      "metadata": {
        "id": "GYkALTy3jUeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write(new_data)"
      ],
      "metadata": {
        "id": "8k88J57HlGbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"output.train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nxR1_umplQaO",
        "outputId": "56b40072-ca00-4fa5-a18c-31e3395897fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c042da4-237d-4044-841c-3cedb5251515\", \"output.train\", 4608449)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}