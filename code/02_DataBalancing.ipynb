{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM62HdWroHa+qWlXAxPZboP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu --quiet"
      ],
      "metadata": {
        "id": "upVURDE_wmXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "from conllu import parse\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "3ri1a4KM2xps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/CLthesis  # first remove clone if necessary"
      ],
      "metadata": {
        "id": "BqiW-io6TZzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/krfis/CLthesis.git --quiet"
      ],
      "metadata": {
        "id": "dhIFJ3kcz_Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getsize_allinfolder(folder_path):\n",
        "  '''prints token counts in all files of a folder'''\n",
        "\n",
        "  for file in os.listdir(folder_path):\n",
        "    path = os.path.join(folder_path, file)\n",
        "    if path.endswith(\".conllu\"):\n",
        "      with open(path, \"r\", encoding=\"utf-8\") as input:\n",
        "        data = input.read()\n",
        "      sentences = parse(data)\n",
        "      print(f'Number of sentences in {path} : {len(sentences)}')\n",
        "      token_count = count_tokens(sentences)\n",
        "      print(f'Number of tokens in {path} : {token_count}')\n",
        "      print()"
      ],
      "metadata": {
        "id": "SWWjKP5_wuQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(dataset):\n",
        "  '''counts tokens in a conllu dataset\n",
        "  returns token count : int'''\n",
        "\n",
        "  counter = 0\n",
        "  for sentence in dataset:\n",
        "    for token in sentence:\n",
        "      counter += 1\n",
        "  return counter"
      ],
      "metadata": {
        "id": "ojwyK6S6JHEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(path):\n",
        "  '''parses conllu file\n",
        "  returns parsed conllu file : list(TokenList)'''\n",
        "\n",
        "  with open(path, \"r\", encoding=\"utf-8\") as dataset:\n",
        "    input = dataset.read()\n",
        "    parsed = parse(input)\n",
        "  return parsed"
      ],
      "metadata": {
        "id": "ny9rltMUi5Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write(content):\n",
        "  '''writes content of TokenLists to output file'''\n",
        "\n",
        "  with open(\"output.train\", \"w\", encoding=\"utf-8\") as output:\n",
        "    for sent in content:\n",
        "      output.write(sent.serialize())"
      ],
      "metadata": {
        "id": "CPnL16d3kyF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_options = ['mono', 'merge']  # mono = a single treebank, merge = a combination of two treebanks\n",
        "task = task_options[0]  # change here\n",
        "task"
      ],
      "metadata": {
        "id": "em179_D1me_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path to file(s)\n",
        "\n",
        "file1 = \"/content/CLthesis/data/filtered/dev-sets/slv-filtered.dev\"\n",
        "file2 = \"\""
      ],
      "metadata": {
        "id": "CrOMMzg-iR5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if task == \"mono\":\n",
        "  data1 = process(file1)\n",
        "elif task == \"merge\":\n",
        "  data1 = process(file1)\n",
        "  data2 = process(file2)"
      ],
      "metadata": {
        "id": "obe38RGNjFu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if task == \"mono\":\n",
        "  print(f'Number of sentences: {len(data1)}')\n",
        "  token_count = count_tokens(data1)\n",
        "  print(f'Number of tokens: {token_count}')\n",
        "elif task == \"merge\":\n",
        "  print(f'Number of sentences: {len(data1)}')\n",
        "  token_count1 = count_tokens(data1)\n",
        "  print(f'Number of tokens: {token_count1}')\n",
        "  print(f'************')\n",
        "  print(f'Number of sentences: {len(data2)}')\n",
        "  token_count2 = count_tokens(data2)\n",
        "  print(f'Number of tokens: {token_count2}')"
      ],
      "metadata": {
        "id": "EqjWVwwkjTZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if task == \"mono\":\n",
        "  sample_from = data1\n",
        "\n",
        "elif task == \"merge\":\n",
        "  sample_from1 = data1\n",
        "  sample_from2 = data2\n",
        "\n",
        "  print(count_tokens(sample_from1))\n",
        "  print(count_tokens(sample_from2))\n",
        "\n",
        "  sample_from = sample_from1 + sample_from2"
      ],
      "metadata": {
        "id": "Tu-zSoJam2MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_from)"
      ],
      "metadata": {
        "id": "LUYMaVKLOABs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_from[0]"
      ],
      "metadata": {
        "id": "b4szVsLUkZKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(0, (len(sample_from)+1)):\n",
        "  rdm_choice = random.sample(sample_from, k=n)\n",
        "  tkns = count_tokens(rdm_choice)\n",
        "  check = False\n",
        "  if tkns <= 14900 or tkns >= 15100:  # change numbers here depending on dataset\n",
        "    check = False\n",
        "  else:\n",
        "    check = True\n",
        "  if check:\n",
        "    print(f'Sampled enough tokens, assignig data from {n} sentences')\n",
        "    new_data = rdm_choice\n",
        "    break\n",
        "  elif n == len(sample_from) and not check:\n",
        "    print(f\"Couldn't find sample\")"
      ],
      "metadata": {
        "id": "jAmGarNa9ZUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'THE FINAL DATA SET')\n",
        "print(f'Number of sentences: {len(new_data)}')\n",
        "token_count_new = count_tokens(new_data)\n",
        "print(f'Number of tokens: {token_count_new}')"
      ],
      "metadata": {
        "id": "zDzGHB3lkogm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data[0]"
      ],
      "metadata": {
        "id": "xFPbcae_rubl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write(new_data)"
      ],
      "metadata": {
        "id": "8k88J57HlGbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"output.train\")"
      ],
      "metadata": {
        "id": "MrAHRjyrylAx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1e8a525c-db3c-4977-ae20-f1d39bb33c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_50697257-f0c1-4f2b-8dbe-8b467330e10c\", \"output.train\", 75611)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}